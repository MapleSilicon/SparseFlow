# SparseFlow

> **Compiler-Driven Sparse Tensor Inference**  
> Automatic sparsity detection and exploitation for 3-5Ã— faster neural network inference

[![License](https://img.shields.io/badge/license-MIT-blue.svg)](LICENSE)
[![Version](https://img.shields.io/badge/version-0.1.0-green.svg)](CHANGELOG.md)
[![MLIR](https://img.shields.io/badge/MLIR-19.x-orange.svg)](https://mlir.llvm.org/)

**GitHub**: [MapleSilicon/SparseFlow](https://github.com/MapleSilicon/SparseFlow)

---

## ğŸš€ What is SparseFlow?

SparseFlow is an **MLIR-based compiler** that automatically detects and exploits structured sparsity in neural networks, delivering **3-5Ã— speedups** on commodity hardware with **zero accuracy loss**.

Unlike runtime-based solutions, SparseFlow performs **static sparsity analysis at compile time**, eliminating profiling overhead and guaranteeing correctness.

---

## âš¡ Performance

**Proven speedups on 50% structured sparsity (2:4 pattern):**
```
Matrix Size | Dense Time | Sparse Time | Speedup
------------|------------|-------------|--------
  128Ã—128   |   2.21 ms  |   0.54 ms   |  4.09Ã—
  256Ã—256   |  20.24 ms  |   5.33 ms   |  3.80Ã—
  512Ã—512   | 247.74 ms  |  54.49 ms   |  4.55Ã—
 1024Ã—1024  |2575.15 ms  | 713.08 ms   |  3.61Ã—
```

**Average: 4Ã— faster with 75% fewer operations**

---

## ğŸ¯ Quick Start

### Prerequisites

- LLVM/MLIR 19.x
- CMake 3.20+
- C++17 compiler
- OpenMP (for runtime)

### Build
```bash
# Clone repository
git clone https://github.com/MapleSilicon/SparseFlow
cd SparseFlow

# Build compiler
cd compiler/build
cmake .. -DMLIR_DIR=/usr/lib/llvm-19/lib/cmake/mlir \
         -DLLVM_DIR=/usr/lib/llvm-19/lib/cmake/llvm
make -j8

# Build runtime
cd ../../runtime/build
cmake ..
make -j8
```

### Run Demo
```bash
cd ~/src/SparseFlow
./run_sparseflow_demo.sh
```

**Output:**
```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘           SparseFlow Compiler Demo v0.1                       â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

âœ… Correctness: 4/4 tests passed
âœ… Performance: 3.6-4.5Ã— speedup achieved
âœ… Pipeline: Complete end-to-end execution
```

---

## ğŸ—ï¸ Architecture
```
Input MLIR
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  SPA Analysis       â”‚  â† Detects sparsity patterns
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Rewrite Pass       â”‚  â† Converts to sparse ops
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  LLVM Lowering      â”‚  â† Generates native code
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  JIT Execution      â”‚  â† Runs with runtime kernel
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
Output (4Ã— faster)
```

---

## ğŸ”¬ Technical Highlights

### Sparsity Propagation Analysis (SPA)
- **Static analysis** - No runtime profiling needed
- **2D mask propagation** - Tracks row & column sparsity
- **Correctness guaranteed** - Conservative analysis

### Automatic Rewriting
- Converts `linalg.matmul` â†’ `@sparse_matmul_2_4`
- Preserves semantics
- Generates efficient runtime calls

### Optimized Runtime
- **OpenMP parallelization** - Multi-core CPU execution
- **Cache-optimized** - Skips zero blocks
- **Vectorized** - SIMD instructions

---

## ğŸ“Š Benchmarks

Run comprehensive benchmarks:
```bash
cd compiler/build
./benchmark_suite
```

Validate correctness:
```bash
./test_jit_correctness
```

---

## ğŸ—ºï¸ Roadmap

See [ROADMAP.md](ROADMAP.md) for detailed development plan.

**Next milestones:**
- **v0.2** (Q1 2025): N:M generalized sparsity, Python API
- **v0.3** (Q2 2025): GPU acceleration (CUDA kernels)
- **v0.4** (Q2-Q3 2025): Real neural networks
- **v0.5** (Q3 2025): PyTorch integration
- **v1.0** (Q4 2025): Production release

---

## ğŸ¤ Contributing

We welcome contributions! Areas of interest:

- MLIR compiler passes
- CUDA/ROCm kernels
- PyTorch/ONNX integration
- Benchmark development
- Documentation

See our [issues](https://github.com/MapleSilicon/SparseFlow/issues) for current tasks.

---

## ğŸ“„ License

MIT License - See LICENSE file for details

---

## ğŸ“« Contact

- **Email**: maplesilicon1@gmail.com
- **GitHub Issues**: [MapleSilicon/SparseFlow/issues](https://github.com/MapleSilicon/SparseFlow/issues)
- **GitHub Discussions**: [MapleSilicon/SparseFlow/discussions](https://github.com/MapleSilicon/SparseFlow/discussions)

---

*SparseFlow v0.1.0 - Making sparse inference fast and automatic*
